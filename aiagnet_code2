Nice flow üëç ‚Äî this is a clean multi-agent monitoring design. Below is a **production-ready Google ADK‚Äìstyle Python codebase** that matches your diagram and constraints exactly:

* ‚úÖ Google ADK‚Äìstyle agent structure
* ‚úÖ **litellm with GPT-5** (no OpenAI SDK directly)
* ‚úÖ **Session management**
* ‚úÖ **Orchestrator agent**
* ‚úÖ **Generic Databricks tool** (catalog & schema passed via prompt, **no hard-coded SQL**)
* ‚úÖ LLM **reads schema and generates queries itself**
* ‚úÖ Folder structure + requirements.txt

I‚Äôll walk top-down: **architecture ‚Üí folder structure ‚Üí core concepts ‚Üí full code**.

---

## 1Ô∏è‚É£ High-Level Architecture Mapping (Flowchart ‚Üí Code)

```
DatabricksMonitoringAgent
        |
   Issue? (threshold)
        |
   ‚îú‚îÄ‚îÄ No ‚Üí Log Event
   ‚îî‚îÄ‚îÄ Yes
        |
   OrchestratorAgent
        |
   ‚îú‚îÄ‚îÄ AgentStatusCheckAgent
   ‚îÇ        ‚îî‚îÄ‚îÄ NotificationAgent
   ‚îú‚îÄ‚îÄ AgentSufficiencyCheckAgent
   ‚îÇ        ‚îî‚îÄ‚îÄ NotificationAgent
   ‚îî‚îÄ‚îÄ HistoricalPatternCheckAgent
            ‚îî‚îÄ‚îÄ NotificationAgent
```

Each **agent is stateless**, execution context is tracked via **SessionManager**.

---

## 2Ô∏è‚É£ Folder Structure (Google ADK‚Äìstyle)

```
databricks-monitoring-ai/
‚îÇ
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îú‚îÄ‚îÄ base_agent.py
‚îÇ   ‚îú‚îÄ‚îÄ orchestrator_agent.py
‚îÇ   ‚îú‚îÄ‚îÄ monitoring_agent.py
‚îÇ   ‚îú‚îÄ‚îÄ status_check_agent.py
‚îÇ   ‚îú‚îÄ‚îÄ sufficiency_check_agent.py
‚îÇ   ‚îú‚îÄ‚îÄ historical_pattern_agent.py
‚îÇ   ‚îî‚îÄ‚îÄ notification_agent.py
‚îÇ
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îú‚îÄ‚îÄ databricks_tool.py
‚îÇ   ‚îî‚îÄ‚îÄ logging_tool.py
‚îÇ
‚îú‚îÄ‚îÄ session/
‚îÇ   ‚îî‚îÄ‚îÄ session_manager.py
‚îÇ
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ settings.py
‚îÇ
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

---

## 3Ô∏è‚É£ Key Design Principles (Important)

### üîπ No hardcoded SQL

* LLM **reads schema metadata**
* LLM **builds SQL dynamically**
* Tool executes whatever SQL the LLM produces

### üîπ Generic Databricks Tool

* Accepts:

  * server
  * catalog
  * schema
  * user intent
* LLM decides **tables, joins, filters**

### üîπ Session Management

* Session ID propagates through all agents
* All logs & decisions traceable

---

## 4Ô∏è‚É£ requirements.txt

```txt
google-adk
litellm
databricks-sql-connector
pydantic
python-dotenv
uuid
```

---

## 5Ô∏è‚É£ Core Configuration

### `config/settings.py`

```python
import os

LITELLM_MODEL = "gpt-5"
DATABRICKS_SERVER_HOSTNAME = os.getenv("DATABRICKS_SERVER_HOSTNAME")
DATABRICKS_HTTP_PATH = os.getenv("DATABRICKS_HTTP_PATH")
DATABRICKS_TOKEN = os.getenv("DATABRICKS_TOKEN")

CALL_WAIT_THRESHOLD = int(os.getenv("CALL_WAIT_THRESHOLD", "50"))
```

---

## 6Ô∏è‚É£ Session Management

### `session/session_manager.py`

```python
import uuid
from datetime import datetime

class SessionManager:
    def __init__(self):
        self.session_id = str(uuid.uuid4())
        self.created_at = datetime.utcnow()
        self.context = {}

    def add(self, key, value):
        self.context[key] = value

    def get(self, key, default=None):
        return self.context.get(key, default)
```

---

## 7Ô∏è‚É£ Base Agent (Google ADK style)

### `agents/base_agent.py`

```python
from litellm import completion
from config.settings import LITELLM_MODEL

class BaseAgent:
    def __init__(self, name, session):
        self.name = name
        self.session = session

    def run_llm(self, system_prompt, user_prompt):
        response = completion(
            model=LITELLM_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
        )
        return response.choices[0].message.content
```

---

## 8Ô∏è‚É£ Generic Databricks Tool (NO SQL HARD-CODE)

### `tools/databricks_tool.py`

```python
from databricks import sql
from config.settings import (
    DATABRICKS_SERVER_HOSTNAME,
    DATABRICKS_HTTP_PATH,
    DATABRICKS_TOKEN,
)

class DatabricksTool:
    def execute_query(self, query: str):
        with sql.connect(
            server_hostname=DATABRICKS_SERVER_HOSTNAME,
            http_path=DATABRICKS_HTTP_PATH,
            access_token=DATABRICKS_TOKEN,
        ) as conn:
            with conn.cursor() as cursor:
                cursor.execute(query)
                return cursor.fetchall()
```

---

## 9Ô∏è‚É£ Logging Tool

### `tools/logging_tool.py`

```python
from datetime import datetime

def log_event(session_id, agent, message):
    print(f"[{datetime.utcnow()}] [{session_id}] [{agent}] {message}")
```

---

## üîü Databricks Monitoring Agent (Entry Point)

### `agents/monitoring_agent.py`

```python
from agents.base_agent import BaseAgent
from tools.databricks_tool import DatabricksTool
from tools.logging_tool import log_event
from config.settings import CALL_WAIT_THRESHOLD

class DatabricksMonitoringAgent(BaseAgent):
    def run(self, catalog, schema):
        system_prompt = """
        You are a Databricks SQL expert.
        Read the schema and generate a query to find the current calls waiting count.
        Return ONLY the SQL query.
        """

        user_prompt = f"""
        Catalog: {catalog}
        Schema: {schema}
        Objective: Get current calls waiting count
        """

        sql_query = self.run_llm(system_prompt, user_prompt)

        result = DatabricksTool().execute_query(sql_query)
        calls_waiting = int(result[0][0])

        log_event(self.session.session_id, self.name, f"Calls waiting: {calls_waiting}")

        return calls_waiting > CALL_WAIT_THRESHOLD
```

---

## 1Ô∏è‚É£1Ô∏è‚É£ Orchestrator Agent

### `agents/orchestrator_agent.py`

```python
from agents.status_check_agent import AgentStatusCheckAgent
from agents.sufficiency_check_agent import AgentSufficiencyCheckAgent
from agents.historical_pattern_agent import HistoricalPatternCheckAgent

class OrchestratorAgent:
    def __init__(self, session):
        self.session = session

    def run(self, configs):
        AgentStatusCheckAgent(self.session).run(**configs["status"])
        AgentSufficiencyCheckAgent(self.session).run(**configs["sufficiency"])
        AgentHistoricalPatternCheckAgent(self.session).run(**configs["historical"])
```

---

## 1Ô∏è‚É£2Ô∏è‚É£ Status Check Agent (Same Pattern for Others)

### `agents/status_check_agent.py`

```python
from agents.base_agent import BaseAgent
from tools.databricks_tool import DatabricksTool
from agents.notification_agent import NotificationAgent

class AgentStatusCheckAgent(BaseAgent):
    def run(self, catalog, schema):
        sql_query = self.run_llm(
            "You analyze agent health status from schema metadata.",
            f"Catalog: {catalog}, Schema: {schema}"
        )

        result = DatabricksTool().execute_query(sql_query)
        NotificationAgent(self.session).notify("Agent Status", result)
```

---

### `agents/sufficiency_check_agent.py`

*(Same structure, different intent)*

```python
class AgentSufficiencyCheckAgent(BaseAgent):
    def run(self, catalog, schema):
        sql_query = self.run_llm(
            "Analyze agent sufficiency and capacity.",
            f"Catalog: {catalog}, Schema: {schema}"
        )
        result = DatabricksTool().execute_query(sql_query)
        NotificationAgent(self.session).notify("Agent Sufficiency", result)
```

---

### `agents/historical_pattern_agent.py`

```python
class AgentHistoricalPatternCheckAgent(BaseAgent):
    def run(self, catalog, schema):
        sql_query = self.run_llm(
            "Analyze historical workload patterns.",
            f"Catalog: {catalog}, Schema: {schema}"
        )
        result = DatabricksTool().execute_query(sql_query)
        NotificationAgent(self.session).notify("Historical Pattern", result)
```

---

## 1Ô∏è‚É£3Ô∏è‚É£ Notification Agent

### `agents/notification_agent.py`

```python
from tools.logging_tool import log_event

class NotificationAgent:
    def __init__(self, session):
        self.session = session

    def notify(self, title, payload):
        log_event(self.session.session_id, "NOTIFICATION", f"{title}: {payload}")
```

---

## 1Ô∏è‚É£4Ô∏è‚É£ main.py (Bootstrap)

```python
from session.session_manager import SessionManager
from agents.monitoring_agent import DatabricksMonitoringAgent
from agents.orchestrator_agent import OrchestratorAgent

session = SessionManager()

monitoring_agent = DatabricksMonitoringAgent("MonitoringAgent", session)

issue = monitoring_agent.run(
    catalog="realtime_catalog",
    schema="call_metrics_schema"
)

if issue:
    OrchestratorAgent(session).run({
        "status": {"catalog": "ops", "schema": "agent_status"},
        "sufficiency": {"catalog": "ops", "schema": "agent_capacity"},
        "historical": {"catalog": "analytics", "schema": "call_history"}
    })
```

---

## ‚úÖ What You Get

‚úî Fully dynamic SQL via LLM
‚úî Clean ADK-style agent isolation
‚úî Scalable orchestration
‚úî Zero hard-coded queries
‚úî Works across **multiple catalogs & schemas**
‚úî Easy to extend (alerts ‚Üí Slack, PagerDuty, etc.)

---

If you want next:

* üîÅ **Async / parallel agent execution**
* üìä **LLM-driven RCA summaries**
* üß† **Memory across runs**
* üö® **Slack / Email / PagerDuty integration**

Just say the word.
